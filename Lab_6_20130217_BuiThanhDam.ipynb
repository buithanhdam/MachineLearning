{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BuiThanhDam02/ML2023/blob/main/Lab_6_20130217_BuiThanhDam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with classification task using **Random Forests** and **Naïve Bayes** algorithms with/without **Feature Selection**. \n",
        "\n",
        "*   **Deadline: 23:59, 25/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from prettytable import  PrettyTable\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.feature_selection import SelectFromModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Task 1. Compare the performance of selected classification algorithms including **Random forest**, **NaiveBayes**, and **SVM** with **mnist** dataset based on **accuracy, precision, recall, f1** measures according to **without using selection feature** and **using selection feature**.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "mnist = datasets.load_digits()\n",
        "Xtrain = mnist['data']\n",
        "ytrain = mnist['target']\n",
        "\n",
        "svm = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "svm.fit(Xtrain, ytrain)\n",
        "x_trainSVM, x_testSVM, y_trainSVM, y_testSVM = train_test_split(Xtrain,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predSVM = svm.predict(x_testSVM)\n",
        "\n",
        "accSvm =  accuracy_score(y_testSVM, y_predSVM)\n",
        "preSvm= metrics.precision_score(y_testSVM, y_predSVM,average='macro')\n",
        "\n",
        "recallSvm= metrics.recall_score(y_testSVM, y_predSVM,average='macro')\n",
        "f1Svm = metrics.f1_score(y_testSVM, y_predSVM,average='macro') "
      ],
      "metadata": {
        "id": "sOsg77IBzEyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Create a Random Forest Classifier\n",
        "rfc=RandomForestClassifier(n_estimators=100)\n",
        "#Train the model using the training sets\n",
        "rfc.fit(Xtrain,ytrain)\n",
        "x_trainRFC, x_testRFC, y_trainRFC, y_testRFC = train_test_split(Xtrain,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predRFC = rfc.predict(x_testRFC)\n",
        "\n",
        "accRFC =  accuracy_score(y_testRFC, y_predRFC)\n",
        "preRFC= metrics.precision_score(y_testRFC, y_predRFC,average='macro')\n",
        "\n",
        "recallRFC= metrics.recall_score(y_testRFC, y_predRFC,average='macro')\n",
        "f1RFC = metrics.f1_score(y_testRFC, y_predRFC,average='macro') "
      ],
      "metadata": {
        "id": "NfiJeB-YzYo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(Xtrain, ytrain)\n",
        "\n",
        "x_trainNB, x_testNB, y_trainNB, y_testNB = train_test_split(Xtrain,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predNB = nb.predict(x_testNB)\n",
        "\n",
        "accNB =  accuracy_score(y_testNB, y_predNB)\n",
        "preNB= metrics.precision_score(y_testNB, y_predNB,average='macro')\n",
        "\n",
        "recallNB= metrics.recall_score(y_testNB, y_predNB,average='macro')\n",
        "f1NB = metrics.f1_score(y_testNB, y_predNB,average='macro') "
      ],
      "metadata": {
        "id": "0qQHSwqWzaS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#svm using selection feature\n",
        "Xtrain_new = SelectKBest(chi2, k=20).fit_transform(Xtrain, ytrain)\n",
        "\n",
        "svm.fit(Xtrain_new, ytrain)\n",
        "x_trainSVMs, x_testSVMs, y_trainSVMs, y_testSVMs = train_test_split(Xtrain_new,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predSVMs = svm.predict(x_testSVMs)\n",
        "\n",
        "accSvms =  accuracy_score(y_testSVMs, y_predSVMs)\n",
        "preSvms= metrics.precision_score(y_testSVMs, y_predSVMs,average='macro')\n",
        "\n",
        "recallSvms= metrics.recall_score(y_testSVMs, y_predSVMs,average='macro')\n",
        "f1Svms = metrics.f1_score(y_testSVMs, y_predSVMs,average='macro') \n"
      ],
      "metadata": {
        "id": "bYsUDe7D_SAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rfc using selection feature\n",
        "rfc.fit(Xtrain_new,ytrain)\n",
        "x_trainRFCs, x_testRFCs, y_trainRFCs, y_testRFCs = train_test_split(Xtrain_new,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predRFCs = rfc.predict(x_testRFCs)\n",
        "\n",
        "accRFCs =  accuracy_score(y_testRFCs, y_predRFCs)\n",
        "preRFCs= metrics.precision_score(y_testRFCs, y_predRFCs,average='macro')\n",
        "\n",
        "recallRFCs= metrics.recall_score(y_testRFCs, y_predRFCs,average='macro')\n",
        "f1RFCs = metrics.f1_score(y_testRFCs, y_predRFCs,average='macro') \n"
      ],
      "metadata": {
        "id": "-NJT8f1SA3Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nb using selection feature\n",
        "\n",
        "nb.fit(Xtrain_new, ytrain)\n",
        "\n",
        "x_trainNBs, x_testNBs, y_trainNBs, y_testNBs = train_test_split(Xtrain_new,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predNBs = nb.predict(x_testNBs)\n",
        "\n",
        "accNBs =  accuracy_score(y_testNBs, y_predNBs)\n",
        "preNBs= metrics.precision_score(y_testNBs, y_predNBs,average='macro')\n",
        "\n",
        "recallNBs= metrics.recall_score(y_testNBs, y_predNBs,average='macro')\n",
        "f1NBs = metrics.f1_score(y_testNBs, y_predNBs,average='macro') \n"
      ],
      "metadata": {
        "id": "rIvtHZC9BVXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = PrettyTable(['Name Metric measure','SVM','Random Forest',\"Naive Bayes (Gaussian)\"])\n",
        "t.add_row(['Accuracy',accSvm,accRFC,accNB])\n",
        "t.add_row(['Precision Score',preSvm,preRFC,preNB])\n",
        "t.add_row(['Recall Score',recallSvm,recallRFC,recallNB])\n",
        "t.add_row(['F1',f1Svm,f1RFC,f1NB])\n",
        "print('Without using selection features')\n",
        "print(t)\n",
        "\n",
        "t2 = PrettyTable(['Name Metric measure','SVM','Random Forest',\"Naive Bayes (Gaussian)\"])\n",
        "t2.add_row(['Accuracy',accSvms,accRFCs,accNBs])\n",
        "t2.add_row(['Precision Score',preSvms,preRFCs,preNBs])\n",
        "t2.add_row(['Recall Score',recallSvms,recallRFCs,recallNBs])\n",
        "t2.add_row(['F1',f1Svms,f1RFCs,f1NBs])\n",
        "print('Using selection features')\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4m7il6sBmGB",
        "outputId": "47c5dd87-86df-4406-ad2a-d273d9a411fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without using selection features\n",
            "+---------------------+-----+---------------+------------------------+\n",
            "| Name Metric measure | SVM | Random Forest | Naive Bayes (Gaussian) |\n",
            "+---------------------+-----+---------------+------------------------+\n",
            "|       Accuracy      | 1.0 |      1.0      |   0.8425925925925926   |\n",
            "|   Precision Score   | 1.0 |      1.0      |   0.8754996278813421   |\n",
            "|     Recall Score    | 1.0 |      1.0      |   0.8432015187160523   |\n",
            "|          F1         | 1.0 |      1.0      |   0.8469725015266443   |\n",
            "+---------------------+-----+---------------+------------------------+\n",
            "Using selection features\n",
            "+---------------------+--------------------+---------------+------------------------+\n",
            "| Name Metric measure |        SVM         | Random Forest | Naive Bayes (Gaussian) |\n",
            "+---------------------+--------------------+---------------+------------------------+\n",
            "|       Accuracy      | 0.9944444444444445 |      1.0      |   0.7851851851851852   |\n",
            "|   Precision Score   | 0.994745918356451  |      1.0      |   0.832840053703066    |\n",
            "|     Recall Score    | 0.9945419103313838 |      1.0      |   0.7909261566099561   |\n",
            "|          F1         | 0.9946288675872493 |      1.0      |   0.7850502437203137   |\n",
            "+---------------------+--------------------+---------------+------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "For given bank dataset (bank.csv) having the following attributes :\n",
        "1.\t**age** (numeric)\n",
        "2.\t**job** : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3.\t**marital** : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4.\t**education** (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5.\t**default**: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6.\t**housing**: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7.\t**loan**: has personal loan? (categorical: 'no','yes','unknown')\n",
        "8.\t**contact**: contact communication type (categorical: 'cellular','telephone')\n",
        "9.\t**month**: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10.\t**day_of_week**: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11.\t**duration**: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "12.\t**campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13.\t**pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14.\t**previous**: number of contacts performed before this campaign and for this client (numeric)\n",
        "15.\t**poutcome**: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "Output variable (desired target):\n",
        "16.\t**y**. has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/ColabNotebooks'\n",
        "dataset=pd.read_csv(\"bank.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfDHFToY4ePI",
        "outputId": "02eab108-c31c-4018-eaf4-7f57187d0e97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/ColabNotebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.1. Apply StandardScaler() function to columns that contains numerical data ('age', 'balance', 'day', 'campaign', 'pdays', 'previous')"
      ],
      "metadata": {
        "id": "q89LEvT7dqaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "\n",
        "scaler = StandardScaler();\n",
        "dataset[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']] = scaler.fit_transform(dataset[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']])\n",
        "print(dataset[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']])\n"
      ],
      "metadata": {
        "id": "8vx3mfIidu4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f87b3c-e57d-4303-9f4a-2f9fe1c05c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            age   balance       day  campaign     pdays  previous\n",
            "0      1.491505  0.252525 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "1      1.239676 -0.459974 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "2     -0.019470 -0.080160 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "3      1.155733  0.293762 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "4      1.071790 -0.416876 -1.265746 -0.186785 -0.481184 -0.363260\n",
            "...         ...       ...       ...       ...       ...       ...\n",
            "11157 -0.691015 -0.473616  0.515650 -0.554168 -0.481184 -0.363260\n",
            "11158 -0.187357 -0.246658  0.040612  0.547981 -0.481184 -0.363260\n",
            "11159 -0.774958 -0.464934  0.396891 -0.186785 -0.481184 -0.363260\n",
            "11160  0.148416 -0.473926 -0.909466 -0.186785  1.109571  1.818332\n",
            "11161 -0.607072 -0.473926 -0.790707 -0.554168 -0.481184 -0.363260\n",
            "\n",
            "[11162 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.2. Apply Encode Categorical Value (OneHotEncoder) to transfrom categorical data to numerical data ('job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome')"
      ],
      "metadata": {
        "id": "r7acR0TxdvY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "\n",
        "\n",
        "\n",
        "encode_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "onehotencoder = OneHotEncoder()\n",
        "onehotencoder.fit(dataset[encode_cols])\n",
        "onehot_encoded = onehotencoder.transform(dataset[encode_cols]).toarray()\n",
        "onehot_encoded_df = pd.DataFrame(onehot_encoded, columns=onehotencoder.get_feature_names_out(encode_cols))\n",
        "dataset = pd.concat([dataset, onehot_encoded_df], axis=1)\n",
        "dataset = dataset.drop(encode_cols, axis=1)"
      ],
      "metadata": {
        "id": "egtgBmAtd0um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.3. Apply **Decision tree, Random forest, kNN, NaïveBayes** to preproceed dataset in the previous steps. Then compare the obtained results using **accuracy, precision, recall, f1** measures."
      ],
      "metadata": {
        "id": "K2Si6d69d1nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision tree\n",
        "xtrain = dataset.drop('deposit', axis=1)\n",
        "ytrain = dataset['deposit']\n",
        "\n",
        "DT = DecisionTreeClassifier(criterion=\"gini\", random_state=42, max_depth=5, min_samples_leaf=10)\n",
        "DT.fit(xtrain, ytrain)\n",
        "x_trainDT, x_testDT, y_trainDT, y_testDT = train_test_split(xtrain,ytrain, test_size = 0.3, random_state = 30)\n",
        "\n",
        "y_predDT = DT.predict(x_testDT)\n",
        "\n",
        "accDT =  accuracy_score(y_testDT, y_predDT)\n",
        "preDT= metrics.precision_score(y_testDT, y_predDT,average='macro')\n",
        "\n",
        "recallDT= metrics.recall_score(y_testDT, y_predDT,average='macro')\n",
        "f1DT = metrics.f1_score(y_testDT, y_predDT,average='macro') "
      ],
      "metadata": {
        "id": "Ouil-cf_d8jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random forest\n",
        "rfc=RandomForestClassifier(n_estimators=100)\n",
        "#Train the model using the training sets\n",
        "rfc.fit(xtrain,ytrain)\n",
        "x_trainRFC, x_testRFC, y_trainRFC, y_testRFC = train_test_split(xtrain,ytrain, test_size = 0.3, random_state = 30)\n",
        "\n",
        "y_predRFC = rfc.predict(x_testRFC)\n",
        "\n",
        "accRFC =  accuracy_score(y_testRFC, y_predRFC)\n",
        "preRFC= metrics.precision_score(y_testRFC, y_predRFC,average='macro')\n",
        "\n",
        "recallRFC= metrics.recall_score(y_testRFC, y_predRFC,average='macro')\n",
        "f1RFC = metrics.f1_score(y_testRFC, y_predRFC,average='macro') "
      ],
      "metadata": {
        "id": "7RMBrttY3pkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Knn\n",
        "knn = KNeighborsClassifier(n_neighbors=4)\n",
        "knn.fit(xtrain, ytrain)\n",
        "y_predKnnBest = knn.predict(x_testRFC)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "accKnn = accuracy_score(y_testRFC, y_predKnnBest)\n",
        "preKnn = metrics.precision_score(y_testRFC, y_predKnnBest,average='macro')\n",
        "recallKnn= metrics.recall_score(y_testRFC, y_predKnnBest,average='macro')\n",
        "f1Knn = metrics.f1_score(y_testRFC, y_predKnnBest,average='macro') \n"
      ],
      "metadata": {
        "id": "b882x1p63ps0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive bayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(xtrain, ytrain)\n",
        "\n",
        "x_trainNB, x_testNB, y_trainNB, y_testNB = train_test_split(xtrain,ytrain, test_size = 0.3, random_state = 30)\n",
        "\n",
        "y_predNB = nb.predict(x_testNB)\n",
        "\n",
        "accNB =  accuracy_score(y_testNB, y_predNB)\n",
        "preNB= metrics.precision_score(y_testNB, y_predNB,average='macro')\n",
        "\n",
        "recallNB= metrics.recall_score(y_testNB, y_predNB,average='macro')\n",
        "f1NB = metrics.f1_score(y_testNB, y_predNB,average='macro') "
      ],
      "metadata": {
        "id": "bG5FNQmk3p0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#table\n",
        "t3 = PrettyTable(['Name Metric measure','Decision Tree','Random Forest',\"Naive Bayes (Gaussian)\",\"Knn\"])\n",
        "t3.add_row(['Accuracy',accDT,accRFC,accNB,accKnn])\n",
        "t3.add_row(['Precision Score',preDT,preRFC,preNB,preKnn])\n",
        "t3.add_row(['Recall Score',recallDT,recallRFC,recallNB,recallKnn])\n",
        "t3.add_row(['F1',f1DT,f1RFC,f1NB,f1Knn])\n",
        "print('Without using selection features')\n",
        "print(t3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR_AnrIY5YLl",
        "outputId": "96f25aa9-1dab-4f44-a623-0743b4ef12d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without using selection features\n",
            "+---------------------+--------------------+---------------+------------------------+--------------------+\n",
            "| Name Metric measure |   Decision Tree    | Random Forest | Naive Bayes (Gaussian) |        Knn         |\n",
            "+---------------------+--------------------+---------------+------------------------+--------------------+\n",
            "|       Accuracy      | 0.8068080023887728 |      1.0      |   0.7393251716930427   | 0.817258883248731  |\n",
            "|   Precision Score   | 0.8063200259127983 |      1.0      |   0.745320895182588    | 0.8298041977797119 |\n",
            "|     Recall Score    |  0.80781095971925  |      1.0      |   0.7317580574046393   | 0.8096837618786452 |\n",
            "|          F1         | 0.8064401354774249 |      1.0      |   0.7326288550760542   | 0.8122124899215715 |\n",
            "+---------------------+--------------------+---------------+------------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.4. Using selection feature to above dataset, then compare the classification results with those in Task 2.3. "
      ],
      "metadata": {
        "id": "SweVRB4meApP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "\n",
        "sfm = SelectFromModel(rfc, threshold=0.01)\n",
        "Xtrain_new = sfm.fit_transform(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "seFBhqCSeC7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision tree using selecture feature\n",
        "DT = DecisionTreeClassifier(criterion=\"gini\", random_state=42, max_depth=5, min_samples_leaf=10)\n",
        "DT.fit(Xtrain_new, ytrain)\n",
        "x_trainDT, x_testDT, y_trainDT, y_testDT = train_test_split(Xtrain_new,ytrain, test_size = 0.3, random_state = 30)\n",
        "\n",
        "y_predDT = DT.predict(x_testDT)\n",
        "\n",
        "accDT =  accuracy_score(y_testDT, y_predDT)\n",
        "preDT= metrics.precision_score(y_testDT, y_predDT,average='macro')\n",
        "\n",
        "recallDT= metrics.recall_score(y_testDT, y_predDT,average='macro')\n",
        "f1DT = metrics.f1_score(y_testDT, y_predDT,average='macro') "
      ],
      "metadata": {
        "id": "ZH4QBxCK7L16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive bayes using selecture feature\n",
        "nb = GaussianNB()\n",
        "nb.fit(Xtrain_new, ytrain)\n",
        "\n",
        "x_trainNB, x_testNB, y_trainNB, y_testNB = train_test_split(Xtrain_new,ytrain, test_size = 0.3, random_state = 30)\n",
        "\n",
        "y_predNB = nb.predict(x_testNB)\n",
        "\n",
        "accNB =  accuracy_score(y_testNB, y_predNB)\n",
        "preNB= metrics.precision_score(y_testNB, y_predNB,average='macro')\n",
        "\n",
        "recallNB= metrics.recall_score(y_testNB, y_predNB,average='macro')\n",
        "f1NB = metrics.f1_score(y_testNB, y_predNB,average='macro') "
      ],
      "metadata": {
        "id": "3qNPZCAC7L95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Knn using selecture feature\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(Xtrain_new, ytrain)\n",
        "y_predKnnBest = knn.predict(x_testRFC)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "accKnn = accuracy_score(y_testRFC, y_predKnnBest)\n",
        "preKnn = metrics.precision_score(y_testRFC, y_predKnnBest,average='macro')\n",
        "recallKnn= metrics.recall_score(y_testRFC, y_predKnnBest,average='macro')\n",
        "f1Knn = metrics.f1_score(y_testRFC, y_predKnnBest,average='macro') "
      ],
      "metadata": {
        "id": "QKxWVqUJ7MGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random forest using selecture feature\n",
        "rfc=RandomForestClassifier(n_estimators=100)\n",
        "#Train the model using the training sets\n",
        "rfc.fit(Xtrain_new,ytrain)\n",
        "x_trainRFC, x_testRFC, y_trainRFC, y_testRFC = train_test_split(Xtrain_new,ytrain, test_size = 0.3, random_state = 30)\n",
        "\n",
        "y_predRFC = rfc.predict(x_testRFC)\n",
        "\n",
        "accRFC =  accuracy_score(y_testRFC, y_predRFC)\n",
        "preRFC= metrics.precision_score(y_testRFC, y_predRFC,average='macro')\n",
        "\n",
        "recallRFC= metrics.recall_score(y_testRFC, y_predRFC,average='macro')\n",
        "f1RFC = metrics.f1_score(y_testRFC, y_predRFC,average='macro') "
      ],
      "metadata": {
        "id": "O-EmgJ9_7MMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t4 = PrettyTable(['Name Metric measure','Decision Tree','Random Forest',\"Naive Bayes (Gaussian)\",\"Knn\"])\n",
        "t4.add_row(['Accuracy',accDT,accRFC,accNB,accKnn])\n",
        "t4.add_row(['Precision Score',preDT,preRFC,preNB,preKnn])\n",
        "t4.add_row(['Recall Score',recallDT,recallRFC,recallNB,recallKnn])\n",
        "t4.add_row(['F1',f1DT,f1RFC,f1NB,f1Knn])\n",
        "print('Without using selection features')\n",
        "print(t3)\n",
        "print('Using selection features')\n",
        "print(t4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OYHaLuL8kko",
        "outputId": "eaeb95a4-7ed7-4620-db2a-6b0f1bca2100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without using selection features\n",
            "+---------------------+--------------------+---------------+------------------------+--------------------+\n",
            "| Name Metric measure |   Decision Tree    | Random Forest | Naive Bayes (Gaussian) |        Knn         |\n",
            "+---------------------+--------------------+---------------+------------------------+--------------------+\n",
            "|       Accuracy      | 0.8068080023887728 |      1.0      |   0.7393251716930427   | 0.817258883248731  |\n",
            "|   Precision Score   | 0.8063200259127983 |      1.0      |   0.745320895182588    | 0.8298041977797119 |\n",
            "|     Recall Score    |  0.80781095971925  |      1.0      |   0.7317580574046393   | 0.8096837618786452 |\n",
            "|          F1         | 0.8064401354774249 |      1.0      |   0.7326288550760542   | 0.8122124899215715 |\n",
            "+---------------------+--------------------+---------------+------------------------+--------------------+\n",
            "Using selection features\n",
            "+---------------------+--------------------+--------------------+------------------------+--------------------+\n",
            "| Name Metric measure |   Decision Tree    |   Random Forest    | Naive Bayes (Gaussian) |        Knn         |\n",
            "+---------------------+--------------------+--------------------+------------------------+--------------------+\n",
            "|       Accuracy      | 0.8068080023887728 | 0.9997014034040012 |   0.7426097342490295   | 0.820244849208719  |\n",
            "|   Precision Score   | 0.8063200259127983 | 0.9996786632390746 |   0.7531499244375551   | 0.8196600618330967 |\n",
            "|     Recall Score    |  0.80781095971925  | 0.999721293199554  |   0.7335815705800328   | 0.8185964648148347 |\n",
            "|          F1         | 0.8064401354774249 | 0.9996998877244938 |   0.7341035276779957   | 0.819042385824527  |\n",
            "+---------------------+--------------------+--------------------+------------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "For a given dataset in the Lab #5 (**credit card dataset**), perform feature selection and thencompare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression, SVM, Random Forest and NaiveBayes) based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "dataset=pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "Xtrain = dataset.drop('Class', axis=1)\n",
        "ytrain = dataset['Class']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "xtrainS = scaler.fit_transform(Xtrain)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(xtrainS, ytrain, test_size=0.3, random_state=40)\n"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision tree\n",
        "DT = DecisionTreeClassifier(criterion=\"gini\", random_state=40, max_depth=5, min_samples_leaf=10)\n",
        "DT.fit(xtrainS, ytrain)\n",
        "\n",
        "\n",
        "y_predDT = DT.predict(X_test)\n",
        "\n",
        "accDT =  accuracy_score(y_test, y_predDT)\n",
        "preDT= metrics.precision_score(y_test, y_predDT,average='macro')\n",
        "\n",
        "recallDT= metrics.recall_score(y_test, y_predDT,average='macro')\n",
        "f1DT = metrics.f1_score(y_test, y_predDT,average='macro') "
      ],
      "metadata": {
        "id": "3eGoill3HN2W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Knn\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(xtrainS, ytrain)\n",
        "y_predKnnBest = knn.predict(X_test)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "accKnn = accuracy_score(y_test, y_predKnnBest)\n",
        "preKnn = metrics.precision_score(y_test, y_predKnnBest,average='macro')\n",
        "recallKnn= metrics.recall_score(y_test, y_predKnnBest,average='macro')\n",
        "f1Knn = metrics.f1_score(y_test, y_predKnnBest,average='macro') "
      ],
      "metadata": {
        "id": "tssZJytvHN56"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "LR = LogisticRegression(max_iter=1000)\n",
        "LR.fit(xtrainS, ytrain)\n",
        "y_predLR = LR.predict(X_test)\n",
        "accLR = accuracy_score(y_test, y_predLR)\n",
        "preLR = metrics.precision_score(y_test, y_predLR,average='macro')\n",
        "recallLR= metrics.recall_score(y_test, y_predLR,average='macro')\n",
        "f1LR = metrics.f1_score(y_test, y_predLR,average='macro') "
      ],
      "metadata": {
        "id": "xCfVxsk8HN_r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random forest\n",
        "\n",
        "rfc=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "rfc.fit(xtrainS,ytrain)\n",
        "\n",
        "\n",
        "y_predRFC = rfc.predict(X_test)\n",
        "\n",
        "accRFC =  accuracy_score(y_test, y_predRFC)\n",
        "preRFC= metrics.precision_score(y_test, y_predRFC,average='macro')\n",
        "\n",
        "recallRFC= metrics.recall_score(y_test, y_predRFC,average='macro')\n",
        "f1RFC = metrics.f1_score(y_test, y_predRFC,average='macro') "
      ],
      "metadata": {
        "id": "ioa9S2tQHOKP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM poly cái này em dùng Linear nó chạy tới hơn 15 phút luôn nê e sài poly ạạ\n",
        "svm = svm.SVC(kernel='poly') # Poly Kernel\n",
        "\n",
        "svm.fit(xtrainS, ytrain)\n",
        "\n",
        "\n",
        "y_predSVM = svm.predict(X_test)\n",
        "\n",
        "accSvm =  accuracy_score(y_test, y_predSVM)\n",
        "preSvm= metrics.precision_score(y_test, y_predSVM,average='macro')\n",
        "\n",
        "recallSvm= metrics.recall_score(y_test, y_predSVM,average='macro')\n",
        "f1Svm = metrics.f1_score(y_test, y_predSVM,average='macro') "
      ],
      "metadata": {
        "id": "iwEPtu5iLipZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes Gaussion\n",
        "nb = GaussianNB()\n",
        "nb.fit(xtrainS, ytrain)\n",
        "\n",
        "\n",
        "y_predNB = nb.predict(X_test)\n",
        "\n",
        "accNB =  accuracy_score(y_test, y_predNB)\n",
        "preNB= metrics.precision_score(y_test, y_predNB,average='macro')\n",
        "\n",
        "recallNB= metrics.recall_score(y_test, y_predNB,average='macro')\n",
        "f1NB = metrics.f1_score(y_test, y_predNB,average='macro')"
      ],
      "metadata": {
        "id": "teiR2TBPJs8I"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t4 = PrettyTable(['Name Metric measure','Decision Tree','Random Forest',\"Naive Bayes (Gaussian)\",\"Knn\",\"Logictis Regression\",\"SVM\"])\n",
        "t4.add_row(['Accuracy',accDT,accRFC,accNB,accKnn,accLR,accSvm])\n",
        "t4.add_row(['Precision Score',preDT,preRFC,preNB,preKnn,preLR,preSvm])\n",
        "t4.add_row(['Recall Score',recallDT,recallRFC,recallNB,recallKnn,recallLR,recallSvm])\n",
        "t4.add_row(['F1',f1DT,f1RFC,f1NB,f1Knn,f1LR,f1Svm])\n",
        "\n",
        "print(t4)"
      ],
      "metadata": {
        "id": "pbiiCpIwJtB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4b3cda-6a1f-4572-bc3f-dfddfb056312"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+--------------------+---------------+------------------------+--------------------+---------------------+--------------------+\n",
            "| Name Metric measure |   Decision Tree    | Random Forest | Naive Bayes (Gaussian) |        Knn         | Logictis Regression |        SVM         |\n",
            "+---------------------+--------------------+---------------+------------------------+--------------------+---------------------+--------------------+\n",
            "|       Accuracy      | 0.9996605924417448 |      1.0      |   0.9786173238299217   | 0.9996957035684608 |  0.9992977774656788 | 0.9998127406575144 |\n",
            "|   Precision Score   | 0.9750718280443109 |      1.0      |   0.5305296159813748   | 0.9832044114717017 |  0.944712923145425  | 0.9999062364482367 |\n",
            "|     Recall Score    | 0.916631498739816  |      1.0      |   0.9169448245808518   | 0.9202664097878965 |  0.8223992935833824 | 0.9420289855072463 |\n",
            "|          F1         | 0.943930463326573  |      1.0      |   0.5517872623904669   | 0.9495362139641739 |  0.8737737793537554 | 0.9691838830586736 |\n",
            "+---------------------+--------------------+---------------+------------------------+--------------------+---------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}